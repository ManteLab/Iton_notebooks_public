{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise session 8: Dynamical systems\n",
    "\n",
    "In this exercise session, you will get your introduction dynamical systems theories of the brain. To begin with, we will give you an introduction to general dynamical systems before moving to theories about dynamical systems in the brain next week. As always, we're starting with importing our packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!mkdir utils_ex8\n",
    "!wget -P utils_ex8/ https://github.com/ManteLab/Iton_notebooks_public/raw/refs/heads/main/utils_ex8/dynamical_systems_utils.py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils_ex8.dynamical_systems_utils import *\n",
    "from utils_ex8.dynamical_systems_utils import continuous_update\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "from scipy.optimize import fsolve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  1-Dimensional linear systems refresher\n",
    "\n",
    "You might remember 1- and 2-dimensional dynamical systems from high school or introductory university classes. These systems are governed by an ordinary differential equation (ODE) in the form: $\\dot{x} = f(x)$ or $\\frac{dx}{dt} = f(x)$, where $t$ is time. Note that ODEs only describe <b>change</b>, so every ODE also needs a starting point. The starting point is denoted $x(0)$. Next, we will simulate 2 ODEs.\n",
    "\n",
    "1. $\\dot{x} = 1.5x$, $x(0) = 1$\n",
    "2. $\\dot{x} = -1.5x$, $x(0) = 1$\n",
    "\n",
    "\n",
    "<b> A note on simulating ODEs: </b> \n",
    "\n",
    "ODEs are <b>continuous</b> time systems, meaning that they can be evaluated for arbitrarily small windows of time. To do that, we will have to use a so-called \"solver\". Here, we will use [Euler's method.](https://en.wikipedia.org/wiki/Euler_method) We will not go into ODE solvers in detail.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time parameters\n",
    "t0 = 0  # start time\n",
    "tf = 1  # end time\n",
    "dt = 0.01  # time step\n",
    "t = np.arange(t0, tf, dt)  # time array\n",
    "\n",
    "# Initialize arrays to store the solutions\n",
    "x1 = np.zeros_like(t)\n",
    "x2 = np.zeros_like(t)\n",
    "x3 = np.zeros_like(t)\n",
    "\n",
    "# Initial conditions\n",
    "x1[0] = 1 # for ODE 1\n",
    "x2[0] = 1 # for ODE 2\n",
    "\n",
    "# Euler's method for the first ODE: dx/dt = 1.5x\n",
    "for i in range(1, len(t)):\n",
    "    x1[i] = x1[i-1] + dt * (1.5 * x1[i-1])\n",
    "    \n",
    "    # Euler's method for the second ODE: dx/dt = -1.5x\n",
    "    x2[i] = x2[i-1] + dt * (-1.5 * x2[i-1])\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(t, x1, label=r'$\\dot{x} = 1.5x, x(0) = 1$', color='b')\n",
    "plt.plot(t, x2, label=r'$\\dot{x} = -1.5x, x(0) = 1$', color='r')\n",
    "\n",
    "plt.title('ODE Solutions')\n",
    "plt.xlabel('Time (t)')\n",
    "plt.ylabel('x(t)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "**Assignment 1:** One of these systems is called \"unstable\", the other \"attracting\". Can you tell which is which? (yes/no, why?)\n",
    "\n",
    "**Assignment 2:** One other common pattern in dynamical systems is an \"expanding\" system. Can you come up with an equation that only ever grows?\n",
    "\n",
    "\n",
    "As you might have noticed, it's difficult to look at a single trajectory (the lines above) from an ODE, and determine the behaviour (attracting, unstable, etc..). But this becomes more clear when starting the ODE at different locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time parameters\n",
    "t0 = 0  # start time\n",
    "tf = 5  # end time\n",
    "dt = 0.01  # time step\n",
    "t = np.arange(t0, tf, dt)  # time array\n",
    "\n",
    "# Initialize arrays to store the solutions\n",
    "\n",
    "x2 = np.zeros_like(t)\n",
    "\n",
    "# Initial conditions\n",
    "x1[0] = 1 # for ODE 1x1 = np.zeros_like(t)\n",
    "x2[0] = 1 # for ODE 2\n",
    "\n",
    "    \n",
    "\n",
    "# Plot the results\n",
    "f, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "\n",
    "\n",
    "starts = np.linspace(-5, 5, 20)\n",
    "# Euler's method for the first ODE: dx/dt = 1.5x\n",
    "for s in starts:\n",
    "    x1 = np.zeros_like(t)\n",
    "    x1[0] = s # for ODE 1\n",
    "\n",
    "    x2 = np.zeros_like(t)\n",
    "    x2[0] = s # for ODE 1\n",
    "    for i in range(1, len(t)):\n",
    "        x1[i] = x1[i-1] + dt * (1.5 * x1[i-1])\n",
    "        x2[i] = x2[i-1] + dt * (-1.5 * x2[i-1])\n",
    "        \n",
    "\n",
    "\n",
    "    axes[0].plot(t, x1, color='b')\n",
    "    axes[1].plot(t, x2, color='r')\n",
    "\n",
    "\n",
    "axes[0].set_title(r'$\\dot{x} = 1.5x$')\n",
    "axes[1].set_title(r'$\\dot{x} = -1.5x$')\n",
    "axes[0].set_xlabel('Time (t)')\n",
    "axes[1].set_xlabel('Time (t)')\n",
    "\n",
    "axes[0].set_ylabel('x(t)')\n",
    "axes[1].set_ylabel('x(t)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that so far we have only looked at linear systems, but in $\\dot{x} = f(x)$, $f$ does not have to be linear, and can be extremely complex. In real-life applications typically $f$ is actually often highly non-linear. So as we will see later, these functions can have extremely complicated behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  2-Dimensional linear dynamical systems and flowfields\n",
    "\n",
    "It's relatively straightforward to extend an ODE to 2 dimensions. One example would be the system that has both $x$ and $y$ variables:\n",
    "\n",
    "$\\begin{pmatrix}\n",
    "  \\dot{x} \\newline\n",
    "  \\dot{y} \\\\\n",
    "         \\end{pmatrix} = A \\begin{pmatrix}\n",
    "            x \\newline\n",
    "            y \\\\\n",
    "         \\end{pmatrix}$\n",
    "\n",
    "In this system, the $A$ matrix determines the change of both $x$ and $y$, and is therefore called the <b>dynamics matrix</b>. Next, we'll create a 2-dimensional system with our own dynamics matrix. We are giving you two initial conditions and a dynamics matrix. The initial conditions we are giving you are very similar. Try to add some initial conditions to figure out what sort of system we are dealing with (attracting, expanding or unstable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Initial conditions (you can try different initial conditions here)\n",
    "# Initial conditions are structured: (x coordinate, y coordinate)\n",
    "initial_conditions = [(1, 1), (1, 2)]\n",
    "\n",
    "\n",
    "# Define the system matrix A\n",
    "A = np.array([[1, 0],\n",
    "              [0, -1]])\n",
    "\n",
    "# Solve the system for each set of initial conditions\n",
    "for z0 in initial_conditions:\n",
    "    z = np.zeros((len(t), 2))  # z stores both x and y\n",
    "    z[0] = z0  # Initial condition for (x, y)\n",
    "    \n",
    "    # Euler's method using matrix multiplication\n",
    "    for i in range(1, len(t)):\n",
    "        z[i] = z[i-1] + dt * (A @ z[i-1])  # Matrix multiplication (A @ z)\n",
    "\n",
    "        \n",
    "\n",
    "    # Plot the trajectory in the phase space (x, y)\n",
    "    plt.plot(z[:, 0], z[:, 1], label=f'IC: {z0}')\n",
    "\n",
    "# Phase plot settings\n",
    "plt.title('2-dimensional system')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.axhline(0, color='black',linewidth=0.5)\n",
    "plt.axvline(0, color='black',linewidth=0.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "Try a number of different initial conditions. \n",
    "\n",
    "**Assignment 3:** What sort of system are we dealing with (expanding, stable, unstable, contracting)?\n",
    "\n",
    "Once again, you will notice that the structure of dynamics only becomes clear once we plot many different trajectories from many different initial conditions. Instead of going through this manually, we often visualize a system by drawing it's <b>flowfield</b> (sometimes: phase space). A flowfield does not draw individual trajectories, but shows the \"flow\" at specific locations in space by drawing arrows. These arrows represent two things:\n",
    "\n",
    "1. The direction of change $\\dot{x}$ is shown using the direction of arrows\n",
    "2. The speed of change $\\dot{x}$ is shown using the length of the arrows (shorter arrow = smaller changes)\n",
    "\n",
    "\n",
    "**Assignment 4:** Have a look at the flowfield below. It seems clear that arrows become larger towards the edges of the plot, suggesting growth to infinity. However, what suggests that this system actually has a stable point (a point that the system never leaves)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system matrix A\n",
    "A = np.array([[1, 0],\n",
    "              [0, -1]])\n",
    "\n",
    "# Define the system of ODEs\n",
    "def linear_system(X, t=0):\n",
    "    return A @ X\n",
    "\n",
    "_=plot_2d_flowfield(linear_system, title='2-D flowfield')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modes of linear systems\n",
    "\n",
    "In the previous question we asked how you would be able to tell if the system is unstable just by looking at the flowfield. However, this is not a very exact approach. If we have a very complicated system, the dynamics might just be extremely slow, resulting in tiny arrows in the flowfield. To get an exact answer to what type of system we're studying, we find a system's <b>eigenmodes</b>. These eigenmodes can give exact insights into the type of system we're analyzing. In linear systems that have the form $\\dot{x} = Ax + b$, these modes can be extracted by performing an <b>eigendecomposition</b> on the dynamics matrix $A$: $A = Q\\Lambda Q^{-1}$, where $Q$ is a matrix of the eigenvectors of $A$, and $\\Lambda$ a diagonal matrix that contains the corresponding eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the modes of the dynamics matrix\n",
    "# L are the eigenvalues, Q the eigenvectors\n",
    "L, Q = np.linalg.eig(A)\n",
    "#cast to complex\n",
    "L = L.astype(np.complex_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvalues of A are complex-valued. Meaning that they have a real part and an imaginary part. Both the real part and the imaginary part are determined by (or determine) the dynamics of the system. To visualize the eigenvalues we therefore plot them on the unit circle in the complex plane. You will see two things in the following plot:\n",
    "\n",
    "1. The eigenvalues of $A$ do not have an imaginary component (we will see later why)\n",
    "2. The eigenvalues of $A$ are on opposite sides of the circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = plt.figure(figsize=(4, 4))\n",
    "\n",
    "t = np.linspace(0,np.pi*2,100)\n",
    "plt.title('Eigenvalues of A')\n",
    "plt.plot(np.cos(t), np.sin(t), linewidth=1)\n",
    "\n",
    "plt.scatter(L.real, L.imag, label='eigenvalues')\n",
    "plt.xlabel('real part')\n",
    "plt.ylabel('imaginary part')\n",
    "_=plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what's going on here? The first eigenvalue (1, 0) tells us that there are directions in which this system is growing (the x axis). The second eigenvalue (-1, 0) tells us that there is a direction in which our system is shrinking (the y axis of the flowfield). Obviously, a system cannot grow and shrink in the same directions, so these must be two different directions, meaning that in the middle there must be a place with zero change, an <b>unstable fixed point </b>.\n",
    "\n",
    "### But what about the imaginary part?\n",
    "\n",
    "We saw that the real part of the eigenvalues determined either an increase or decrease in the trajectories. But what does the imaginary component of the eigenvalues mean? In the next question we will ask you to find out.\n",
    "In the next section we will give you all the freedom to explore the two eigenvalues of $A$ and values for $b$ in $\\dot{x} = Ax + b$. Run the code below, and then try to answer the questions below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_=interact(interactive_eigval_plot, \n",
    "         real1=FloatSlider(min=-2.0, max=2.0, step=0.1, value=1.0, description='Real 1', continuous_update=continuous_update),\n",
    "         real2=FloatSlider(min=-2.0, max=2.0, step=0.1, value=-1.0, description='Real 2', continuous_update=continuous_update),\n",
    "         imag1=FloatSlider(min=-2.0, max=2.0, step=0.1, value=0.0, description='imag. 1', continuous_update=continuous_update),\n",
    "         imag2=FloatSlider(min=-2.0, max=2.0, step=0.1, value=0.0, description='Imag. 2', continuous_update=continuous_update),\n",
    "         b=FloatSlider(min=-2.0, max=2.0, step=0.1, value=0.0, description='b', continuous_update=continuous_update))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "**Assignment 5:** Try a number of different settings, what does the imaginary part of the eigenvalues of A do?\n",
    "\n",
    "**Assignment 6:** What is \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Noise and fitting dynamics\n",
    "\n",
    "In neuroscience, we often deal with activity from some neurons through time, without knowing the underlying dynamical system. This data might look something like this:\n",
    "\n",
    "\n",
    "\\begin{array}{c|ccccc}\n",
    "   & \\text{0ms} & \\text{1ms} & \\text{2ms} & \\text{3ms} & \\text{4ms} \\\\\n",
    "  \\hline\n",
    "  \\text{Neuron 1 firing rate} & 1 & 0.5 & 0.3 & 1 & 0.8 \\\\\n",
    "  \\text{Neuron 2 firing rate} & 0.3 & 0.6 & 0.5 & 0.9 & 1 \\\\\n",
    "\\end{array}\n",
    "\n",
    "Given a dataset with measurements $x(t) \\in X$ like this, we can infer the underlying dynamical system by fitting a linear system to the data. This is relatively straightforward using least squares optimization on the dynamics matrix:\n",
    "\n",
    "$\\underset{A}{\\operatorname{argmin}}  \\sum_{t} (Ax(t) - x(t+1))^2$. Or in words: we find the dynamics matrix $A$ that minimizes the squared error between the prediction of the next time step $Ax(t)$ and the actual next time step $x(t+1)$. If the data $X$ comes from a linear system, then this procedure is guaranteed to recover the underlying dynamical system <b>locally</b>. <b>However</b>, in the real world, data - and especially neural activity is extremely noisy, meaning that the underlying dynamical system will look more like $\\dot{x} = Ax(t) + \\eta, \\eta \\sim \\psi(t)$. Where $\\eta$ is noise sampled from some probability distribution $\\psi$. If this noise is very strong, then fitting a dynamics matrix $A$ to the data can be very difficult. But that will not stop us from trying! In the next section we will give you some data and ask you to fit a dynamical system to simulated data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this noise level variable\n",
    "NOISE_LEVEL = 5\n",
    "\n",
    "#simulate an unstable system (Ax + noise)\n",
    "noisy_data = simulate_noisy_system(noise_level=NOISE_LEVEL)\n",
    "\n",
    "#fit a dynamics matrix to the noisy data\n",
    "A_fitted = fit_dynamics_matrix_continuous(noisy_data, 0.1)\n",
    "\n",
    "# Define the new fitted system of ODEs\n",
    "def linear_system_fitted(X, t=0):\n",
    "    return (X @ A_fitted) \n",
    "\n",
    "#plot the fitted flowfield and the trajectories\n",
    "plot_2d_flowfield(linear_system_fitted, data=noisy_data, title=f'Fitted linear system, noise level: {NOISE_LEVEL}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "**Assignment 7**: In the cell above, we are taking the unstable system from before, and simulating it with noise (see the four coloured trajectories). Then we are fitting a dynamics matrix (A_fitted) to these four trajectories. Note how well the fitted dynamics fit the true dynamics (see the flowfield). What happens when you increase the noise? Name two things that change when the noise increases. Try the same noise level multiple times.\n",
    "\n",
    "**Assignment 8**: Can you thing of something that might solve the issues you found in the previous question?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. High-dimensional dynamical systems and manifolds\n",
    "\n",
    "So far we have only been looking at 2-dimensional systems. Bot ofcourse, in real life a neuroscientist will probably record from thousands of different neurons, making our datasets closer to something that looks like this\n",
    "\n",
    "\n",
    "\\begin{array}{c|ccccc}\n",
    "   & \\text{0ms} & \\text{1ms} & \\text{2ms} & \\text{3ms} & \\text{4ms} \\\\\n",
    "  \\hline\n",
    "  \\text{Neuron 1 firing rate} & 1 & 0.5 & 0.3 & 1 & 0.8 \\\\\n",
    "  \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "  \\text{Neuron 1020 firing rate} & 0.3 & 0.6 & 0.5 & 0.9 & 1 \\\\\n",
    "\\end{array}\n",
    "\n",
    "Now, visualizing dynamical systems and their flowfields becomes much more complicated. Luckily neural activity often lives in <b>low-dimensional</b> manifolds in high dimensional space. Below you will see an image to illustrate what a low-dimensional manifold is.\n",
    "\n",
    "\n",
    "![manifold](https://raw.githubusercontent.com/ManteLab/Iton_notebooks_public/refs/heads/main/images/gallego_manifold.png)\n",
    "\n",
    "\n",
    "\n",
    "In this figure, we are looking at a 3-dimensional neural space, where every axis (N1, N2, N3) represents the activity of one neuron. But notice, that trajectories of neural activity do not actually occupy the full space. Instead the trajectories live on a 2-dimensional plane (spanned by U1 and U2) inside of the full 3D space. This plane is often called the manifold. This type of behaviour is very common in neural data, so when analyzing high-dimensional neural signals, part of the analysis is often to finding the manifold. It's important to note that a manifold does not have to be a (hyper) plane, it can be any high- or low dimensional shape.\n",
    "\n",
    "### finding the manifold: PCA\n",
    "\n",
    "There are many different ways of finding low-dimensional manifolds in high dimensional spaces. In this exercise, we will only look at one simple example: Principle Component Analysis (PCA). We saw PCA before in the exercise session on neural population analyses, where we used it to quantify the \"dimensionality\" of different activity patterns. In the following example we will give you a dynamical system, and you will have to figure out how high dimensional this system is. Let's start by simulating a noisy three dimensional system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_LEVEL = 10\n",
    "\n",
    "#simulate a 3d system\n",
    "noisy_3d_data =  simulate_noisy_3d_system(NOISE_LEVEL)\n",
    "\n",
    "# Create a figure\n",
    "fig = plt.figure()\n",
    "\n",
    "# Add 3D subplot\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i in range(50):\n",
    "    ax.plot(noisy_3d_data[:, i, 0], noisy_3d_data[:, i, 1], noisy_3d_data[:, i, 2], label='3D Line')\n",
    "\n",
    "ax.set_ylim(-15, 15)\n",
    "ax.set_xlim(-15, 15)\n",
    "ax.set_zlim(-15, 15)\n",
    "\n",
    "ax.set_xlabel('neuron 1')\n",
    "ax.set_ylabel('neuron 2')\n",
    "ax.set_zlabel('neuron 3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can tell, it's already difficult to tell what is going, even in 3 dimensions. So let's apply PCA, and see if we can find dimensions that explain variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_explained, components = pca(noisy_3d_data)\n",
    "plt.scatter(range(3), variance_explained)\n",
    "plt.xlabel('PC Component')\n",
    "plt.ylabel('Variance explained')\n",
    "plt.title('Variance explained per principal component in the noisy 3D system')\n",
    "plt.ylim([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "**Assignment 9**: How many principal components do you need to explain the noisy 3-dimensional data?\n",
    "\n",
    "**Assignment 10**: What does that tell you about the shape of the low-dimensional manifold?\n",
    "\n",
    "**Assignment 11**: The third component is close to zero, but is not zero, why is that?\n",
    "\n",
    "**Assignment 12**: What do you expect to happen to the explained variance if we simulate this system at a higher noise levels? (you can try this by yourself)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Next, we can project the data onto the 2d plane that explains most of the variance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project our 3d data onto the first two components\n",
    "low_d_proj = noisy_3d_data @ components[:, :2]\n",
    "\n",
    "f = plt.figure(figsize=(4, 4))\n",
    "_=plt.plot(low_d_proj[..., 0], low_d_proj[..., 1])\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.title('2d manifold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question:\n",
    "\n",
    "**Assignment 13** We found the 2d manifold that captures most of the data. If we tell you that most initial conditions are far from the origin (0, 0, 0), can you tell what sort of system this probably is?\n",
    "\n",
    "**Assignment 14** How would you confirm that?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Nonlinear dynamics and linearization\n",
    "\n",
    "So far we have been looking at very simple linear systems. And there is only so many things a linear system can do. In the real world, interactions between neurons are often highly non-linear. Below is an example of a nonlinear system that implements a so called \"saddle point\". Have a look at the system below. Try to find out why our previous notions about \"attracting\", \"unstable\"  behaviour do not really apply to this system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the system of equations\n",
    "def saddle_node_system(state):\n",
    "    x, y = state\n",
    "    dxdt = x - x**3\n",
    "    dydt = -y\n",
    "    return np.array([dxdt, dydt])\n",
    "\n",
    "\n",
    "def nonlinear_system(X, t=0):\n",
    "    return X + saddle_node_system(X) * 2\n",
    "\n",
    "\n",
    "plot_2d_flowfield(nonlinear_system, space=np.linspace(-2, 2, 15),title='2-D flowfield of a saddle point system')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed points and slow points \n",
    "\n",
    "So where do we start to analyze a complicated system like this? We can answer this by ruling out parts of the system that are hard to analyze. Notice that at the edges, the system moves very fast. Fast moving dynamics are hard to analyze because the system often spends very little time in regions with fast moving dynamics. Inversely, <b>slow points</b> and <b>fixed points</b> are locations where the dynamics move very slowly and not at all. We will see later why this is important. For now, try to see if you can visually find the fixed points in the plot above, there are 3. In the next cell we will do this algorithmically. Finding fixed points algorithmically is quite straightforward, given that $\\dot{x} = \\mathbf{0}$, we can start with a bunch of guesses $\\hat{x}$, and then optimize these initial guesses to find fixed points: $\\underset{\\hat{x}}{\\operatorname{argmin}}  (\\hat{x} - f(\\hat{x}))^2$, where $f$ is our dynamical system. We will apply this in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General function to compute fixed points\n",
    "def find_fixed_points(system, initial_guess):\n",
    "    \"\"\"\n",
    "    Find fixed points for a given 2D system using a numerical solver.\n",
    "\n",
    "    Parameters:\n",
    "    - system: a function that returns the derivatives [dx/dt, dy/dt] as a numpy array.\n",
    "    - initial_guess: a numpy array with the initial guess for the fixed point.\n",
    "\n",
    "    Returns:\n",
    "    - fixed_point: a numpy array with the coordinates of the fixed point.\n",
    "    \"\"\"\n",
    "    # Define the function for which we want to find the roots (i.e., f(x, y) = 0 and g(x, y) = 0)\n",
    "    def func(state):\n",
    "        return system(state)\n",
    "    \n",
    "    # Use fsolve to find the roots\n",
    "    fixed_point = fsolve(func, initial_guess)\n",
    "    \n",
    "    return fixed_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot flowfield\n",
    "ax = plot_2d_flowfield(nonlinear_system, space=np.linspace(-2, 2, 15),title='Flowfield with discovered fixed points')\n",
    "\n",
    "# make 10 initial random guesses\n",
    "guesses = np.random.randn(20, 2) * 0.75\n",
    "\n",
    "# for each guess, find where (f(x) = x)\n",
    "fixed_points = []\n",
    "for i, guess in enumerate(guesses):\n",
    "    fixed_point = find_fixed_points(nonlinear_system, guess)\n",
    "    fixed_points.append(fixed_point)\n",
    "    ax.scatter(*fixed_point, s=100)\n",
    "\n",
    "#plot initial guesses\n",
    "ax.scatter(*guesses.T, color='red', label='initial guess')\n",
    "plt.legend()\n",
    "\n",
    "#save the unique fixed points\n",
    "unique_fixed_points = np.unique(np.array(fixed_points).round(decimals=2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local linearization\n",
    "\n",
    "In the plot above you can see that we made a bunch of random guesses (in red) about the fixed points and then found the 3 fixed points (coloured circles) by minizing $(f (\\hat{x}) - \\hat{x})^2$. Now we can study the dynamical system in parts. Because the dynamics around fixed points move very slowly, these dynamics are (close to) linear dynamics, meaning that close to fixed points, we can find some matrix $J$ (called the jacobian), such that $\\dot{x} \\approx Jx_{\\text{fixed}}$. This turns $f$ back into a linear system $locally$ around fixed points, meaning that we can now apply our ideas of \"attraction\" and \"instability\" again. This is what we'll do in the next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for point in unique_fixed_points:\n",
    "    print(\"Found fixed point:\", point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, fill in the fixed points, and have a look at the eigenvalues of their respective jacobians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILL IN THIS POINT\n",
    "FIXED_POINT = [0.0, 0.0]\n",
    "\n",
    "\n",
    "\n",
    "jacobian = compute_jacobian(nonlinear_system, np.array(FIXED_POINT))\n",
    "\n",
    "L, _ = np.linalg.eig(jacobian)\n",
    "\n",
    "f = plt.figure(figsize=(4, 4))\n",
    "\n",
    "t = np.linspace(0,np.pi*2,100)\n",
    "plt.title('Eigenvalues of J')\n",
    "plt.plot(np.cos(t), np.sin(t), linewidth=1)\n",
    "\n",
    "plt.scatter(L.real, L.imag, label='eigenvalues')\n",
    "plt.xlabel('real part')\n",
    "plt.ylabel('imaginary part')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question:\n",
    "\n",
    "**Assignment 15** Above you computed the fixed points for a nonlinear system. We found 3 unique fixed points. But the linear dynamics around these fixed points are not all the same. One fixed point has different local dynamics than the other two. Which one?\n",
    "\n",
    "**Assignment 16** Based on the eigenvalues of the fixed point you found in the previous assigment, what sort of dynamics exist around the origin (0,0)?\n",
    "\n",
    "**Assignment 17** What about the other two fixed points? What sort of dynamics exist around those two? How can you tell by the eigenvalues?\n",
    "\n",
    "\n",
    "## Bonus Question (discussed more next lecture):\n",
    "\n",
    "So far we saw how to a linear dynamical system to data. We also saw that this does not always work. This is especially true if your data comes from a highly nonlinear system. Can you think of a model that can fit data from a non linear, high dimensional dynamical system.\n",
    "\n",
    "<details>\n",
    "<Summary>\n",
    "Answers\n",
    "</Summary>\n",
    "\n",
    "Artificial neural networks can be used to do this. Recurrent neural networks (RNNs) are actually a type of nonlinear dynamical system. \n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of this exercise session"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36fb94ecb814ef8b2f03543782b9808078ae505e10f382299fe9eddf56752e5f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ini')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

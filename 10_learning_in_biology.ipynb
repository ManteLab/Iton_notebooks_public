{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManteLab/Iton_notebooks_public/blob/main/10_learning_in_biology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise session 10: Learning in Biology\n",
        "\n",
        "In this exercise session, we will investigate some aspects of learning mechanisms in the brain. First, we will introduce some biological principles, then discuss mathematical models that describe them and finally you will have the opportuniy to simulate these models."
      ],
      "metadata": {
        "id": "d9ZE0ODpd9b0"
      },
      "id": "d9ZE0ODpd9b0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "First, we need to update the widgets since we use a never version than the Colab default.\n"
      ],
      "metadata": {
        "id": "7pq5zofaZ7re"
      },
      "id": "7pq5zofaZ7re"
    },
    {
      "metadata": {
        "id": "96896c5af34d4a4e"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "!pip install -U ipywidgets"
      ],
      "id": "96896c5af34d4a4e"
    },
    {
      "metadata": {
        "id": "d5c8b983f923d193"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we download additional files required by this tutorial."
      ],
      "id": "d5c8b983f923d193"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdca272b3ede1593",
      "metadata": {
        "jupyter": {
          "is_executing": true
        },
        "id": "fdca272b3ede1593"
      },
      "outputs": [],
      "source": [
        "!mkdir utils_ex10\n",
        "!wget -P utils_ex10/ https://github.com/ManteLab/Iton_notebooks_public/raw/refs/heads/main/utils_ex10/stdp.py\n",
        "!wget -P utils_ex10/ https://github.com/ManteLab/Iton_notebooks_public/raw/refs/heads/main/utils_ex10/ltp_ltd.py\n",
        "!wget -P utils_ex10/ https://github.com/ManteLab/Iton_notebooks_public/raw/refs/heads/main/utils_ex10/odor.py\n",
        "!wget -P utils_ex10/ https://github.com/ManteLab/Iton_notebooks_public/raw/refs/heads/main/utils_ex10/odor_plotting.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install dependencies"
      ],
      "metadata": {
        "id": "Vg9uzWz_aDYG"
      },
      "id": "Vg9uzWz_aDYG"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install netgraph"
      ],
      "metadata": {
        "id": "Xlnp_4FcZ1b6"
      },
      "id": "Xlnp_4FcZ1b6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the downloaded files and enable custom widgets"
      ],
      "metadata": {
        "id": "zDV_ROK8aF6P"
      },
      "id": "zDV_ROK8aF6P"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "LUtYjTjxeRxr"
      },
      "id": "LUtYjTjxeRxr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a69aacb166c09732",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-28T12:03:26.843680Z",
          "start_time": "2024-10-28T12:03:26.722443Z"
        },
        "id": "a69aacb166c09732"
      },
      "outputs": [],
      "source": [
        "from utils_ex10.stdp import *\n",
        "from utils_ex10.ltp_ltd import *\n",
        "from utils_ex10.odor_plotting import *"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36af6a71d523476",
      "metadata": {
        "id": "36af6a71d523476"
      },
      "source": [
        "# 1. Short-term plasticty\n",
        "\n",
        "Source: http://www.scholarpedia.org/article/Short-term_synaptic_plasticity\n",
        "\n",
        "Although memory formation in the brain is believed to rely primarily on long-lasting changes in synaptic strength and connectivity, shorter-lived modulation of synaptic strength, known as **short-term plasticity (STP)**, also plays an important role.\n",
        "\n",
        "While some artificial models implement STP, it is often neglected in others. This provides us with an opportunity to extend the content of this course to explore the mechanisms underlying STP.\n",
        "\n",
        "You have covered quite some ground on the matter of STP already during the lecture but let usre-emphasise the concepts again.\n",
        "\n",
        "In brief, STP is a phenomenon where synaptic effi cacy changes dynamically over time based onthe history of presynaptic activity. As the name suggests, these processes are relatively short-lived, typically lasting for a few milliseconds.\n",
        "\n",
        "Before delving into the details of a mathematical model describing STP, we first examine its two primary forms:\n",
        "\n",
        "**Facilitation**\n",
        "Presynaptic neurons prepare vesicles containing neurotransmitters, priming them for release upon the arrival of an action potential. This process involves a complex molecular machinery that we will not discuss in detail here. However, it is important to note that this process is calcium-dependent. With each arriving presynaptic action potential, the level of presynaptic calcium increases.\n",
        "\n",
        "If action potentials arrive in close succession, the calcium from one action potential adds to the residual calcium remaining from earlier ones. This cumulative increase in calcium enhances the probability of vesicle release, as long as vesicles remain available. Consequently, the postsynaptic excitatory postsynaptic potential (EPSP) becomes larger with successive, closely spaced action potentials.\n",
        "\n",
        "**Depletion**\n",
        "In contrast to facilitation, depletion refers to a decrease in synaptic efficacy due to the depletion of readily releasable vesicles. When a presynaptic action potential arrives, it triggers the release of neurotransmitters from vesicles, but the supply of these vesicles is limited. If action potentials occur at a high frequency, vesicles are released faster than they can be replenished. As a result, subsequent action potentials lead to fewer vesicles being available for release, reducing the postsynaptic excitatory postsynaptic potential (EPSP). Depletion is therefore a form of short-term plasticity that reflects a transient limitation in presynaptic resources. This effect depends on the balance between vesicle replenishment rates and the frequency of presynaptic activity.\n",
        "\n",
        "## 1.1 Mathematical model\n",
        "\n",
        "The following differential equations describe the model proposed by Tsodyks and Markramth for Short-term plasticity (STP).\n",
        "The model uses two variables to describe the internal state of a neuron.\n",
        "First, $x$ describes the fraction of available recources (vesicles in the presynapse). Upon the arrival of an action potential, $x$ decreases due to neurotransmitter depletion, while over time, it recovers to 1.0.\n",
        "\n",
        "Secondly, $u$ describes the fraction of utilized resources (of the available resources). Upon the arrival of an action potential it increases due to calcium influx, while it decays back to zero over time. Formally:\n",
        "\n",
        "$$\n",
        "\\frac{du}{dt} = -\\frac{u}{\\tau_f} + U(1 - u^-) \\ \\delta(t - t_{sp})\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{dx}{dt} = \\frac{1 - x}{\\tau_d} - u^+ x^- \\ \\delta(t - t_{sp})\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{dI}{dt} = -\\frac{I}{\\tau_s} + A u^+ x^- \\ \\delta(t - t_{sp})\n",
        "$$\n",
        "\n",
        "where $t_{sp}$ denotes the spike time and $U$ is the increment of $u$ produced by a spike. We define $u^-$ and $x^-$ as the values of $u$ and $x$ just _before_ the spike arrives and $u^+$ as the value of $u$ immediately _after_ the spike.\n",
        "\n",
        "## 1.3 Assignments - Getting a mathematical intuition\n",
        "\n",
        "You can try to understand the formulas intuitively before demonstrating the differential system that they describe using a simulation.\n",
        "\n",
        "For example, the differential equation $\\frac{du}{dt}$ describes how $u$ changes over time $t$.\n",
        "For $u$, the change in time ($\\frac{du}{dt}$) has two terms $-\\frac{u}{\\tau_f}$ and $U(1 - u^-) \\delta(t - t_{sp})$.\n",
        "\n",
        "\n",
        "Let's think about these terms:\n",
        "\n",
        "**Assignment 1:** What does $-\\frac{u}{\\tau_f}$ describe?\n",
        "\n",
        "**Assignment 2:** What does $U(1 - u^-) \\ \\delta(t - t_{sp})$ describe?\n",
        "\n",
        "**Assignment 3:** Why use $u^-$ rather than $u$ in the second term?\n",
        "\n",
        "**Assignment 4:** Given the solution from the last question, think about the two terms in $\\frac{dx}{dt}$. Why use $u^+$ and $x^-$?\n",
        "\n",
        "---\n",
        "\n",
        "You should now have an intuition for the dynamics of the presynaptic neuron's internal states in the model proposed by Tsodyks and Markram\n",
        ".\n",
        "The last equation above describes how the current (EPSP amplitude) in the postsynaptic neuron is affected by STP dynamics.\n",
        "\n",
        "$$\n",
        "\\frac{dI}{dt} = -\\frac{I}{\\tau_s} + A u^+ x^- \\ \\delta(t - t_{sp})\n",
        "$$\n",
        "\n",
        "**Assignment 5:** Think about the two terms in $\\frac{dI}{dt}$. What do they describe?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Demo\n",
        "\n",
        "Below is an interactive demonstration of the model for Short-term plasticity proposed by Tsodyks and Markramth.\n",
        "\n",
        "You can play around with the sliders to change the parameters found in the equations above.\n",
        "\n",
        "As discussed, two dynamics can be observed in STP:\n",
        "\n",
        "1. Short-Term Facilitation (STF): Caused by calcium influxand accumulation, which in terms enhances the neurotransmitter release probability.\n",
        "2. Short-Term Depression (STD): Results from neurotransmitter depletion due to action potentials arriving at too high freqyency.\n",
        "\n",
        "Below, you have two buttons to set the parameters to fit one of these dynamics."
      ],
      "metadata": {
        "id": "A0Glt5TMXhmo"
      },
      "id": "A0Glt5TMXhmo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2c06f16f15be3bb",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-28T12:03:30.187976Z",
          "start_time": "2024-10-28T12:03:29.089141Z"
        },
        "id": "a2c06f16f15be3bb"
      },
      "outputs": [],
      "source": [
        "iplot_InoF_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de412304-58d6-41eb-b789-0ecea8a33142",
      "metadata": {
        "id": "de412304-58d6-41eb-b789-0ecea8a33142"
      },
      "source": [
        "### 1.4.1 Assignments\n",
        "- **Assignment 6:** Try to understand the parameters for \"SPD-dominated\". What are the essential parameter changes? How can we increase the Short-term depression effect? Also, play around with the spike pattern to sharpen your intuition.\n",
        "- **Assignment 7:**  Try to understand the parameters for \"SPF-dominated\". What are the essential parameter changes? How can we increase the Short-term facilitation effect?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7870898c75b86211",
      "metadata": {
        "id": "7870898c75b86211"
      },
      "source": [
        "# 2. Spike-timing-dependent plasticity (STDP)\n",
        "\n",
        "**Spike-timing-dependent plasticity (STDP)** is a neuronal mechanism that describes the <u>change in synaptic strength</u> based on the <u>temporal relationship between pre- and postsynaptic action potentials</u>, or \"spikes.\"\n",
        "\n",
        "If a <u>presynaptic spike consistently precedes a postsynaptic spike</u> within a short interval (10s of ms), the <u>synapse strengthens</u> (**potentiation**). Conversely, if the <u>presynaptic spike follows the postsynaptic spike</u>, the /u>synapse weakens</u> (**depression**). The result is, that connections are likely strenghtened if they have successfully contributed to the postsynaptic neuron's action potential.\n",
        "\n",
        "## 2.1 Mathematical Model\n",
        "\n",
        "The dynamics of weight changes observed in neurons showing **STDP** can be captured using mathematical models. Let $t_{pre}$ be the <u>time when the presynaptic spike</u> occurs and $t_{post}$ the <u>time of the postsynaptic spike</u>. We denote the temporal difference between these spikes as\n",
        "\n",
        "$$\n",
        "\\Delta t = t_{post} - t_{pre} \\text{, where } t > 0\n",
        "$$\n",
        "\n",
        "Since <u>STDP works</u> only if the pre- and postsynaptic neuron fired <u>action potentials within a narrow window of time</u> (if the time difference grows too big, the spikes of both neurons have likely no relationship to each other and should thus not inform changes in synaptic strength).\n",
        "\n",
        "We know from experiments that the size of weight increase (or decrease) can be captured as a function of $\\Delta t$. However, the **relationship is not linear** but **weights rather decreases exponentially** as the value of $\\Delta t$ increases. Thus, the closer $t_{pre}$ and $t_{post}$ are together, the more the weights increase.\n",
        "\n",
        "The positive change of a weight $w_{ij}$ (potentiation) connecting neuron $i$ (firing the presynaptic spike) to neuron $j$ (firing a postsynaptic spike) is defined as\n",
        "\n",
        "$$\n",
        "\\Delta w_{ij} = A_+ \\cdot \\exp\\left({\\frac{-t}{\\tau_+}}\\right)\\text{, where } \\Delta w_{ij} \\geq 0\n",
        "$$\n",
        "\n",
        "where $A_+$ denotes the maximal positive weight change and $\\tau_+$ is a time constant.\n",
        "\n",
        "However, if neuron $j$ fires a spike before neuron $i$, the weight decreases. In that case, $t_{pre}$ describes the firing time of neuron $j$, and $t_{post}$ denotes the firing time of neuron $i$. The negative weight change is defined as\n",
        "\n",
        "$$\n",
        "\\Delta w_{ij} = A_- \\cdot \\exp\\left({\\frac{-t}{\\tau_-}}\\right) \\text{, where } \\Delta w_{ij} \\leq 0\n",
        "$$\n",
        "\n",
        "where $A_-$ denotes the maximal negative weight change and $\\tau_-$ is a time constant.\n",
        "\n",
        "\n",
        "## 2.2 Simulation\n",
        "\n",
        "In the section below we investigate the mathematical model of STDP. You will find two tabs:\n",
        "\n",
        "- In the left tab, you can change the configuration and adjust the parameters $A_+$, $A_-$, $\\tau_+$, and $\\tau_-$. Note that after changing a configuration, you need to save it by pressing the `Update Config` button. However, this will overwrite any previously captured data.\n",
        "- In the right tab, you can define the timing of the spike of neuron $j$ (relative to the neuron $i$) and submit it. After submission, the plots below will be updated.\n",
        "\n",
        "After submitting a spike, three outputs below will be updated. They show:\n",
        "\n",
        "**Calculation**\n",
        "\n",
        "In the first row, you see the calculation of the weight change $\\Delta w_{ij}$. This calculation is updated based on your configuration and the timing of the pre- and postsynaptic spike timing.\n",
        "\n",
        "**Spike Timing**\n",
        "\n",
        "In the second row, you can observe the timing of the spikes. The red line depicts the spike of neuron $i$ and the blue line the spike of neuron $j$. If the spike of neuron $i$ is before the spike of neuron $j$ (red before blue), $\\Delta w_{ij}$ increases, otherwise, it decreases.\n",
        "\n",
        "**Weight Change**\n",
        "\n",
        "In the third row, we keep track of the weight changes. On the y-axis, you can observe the weight change, while on the x-axis, you can see the time difference $\\Delta t$. If there are multiple registered spikes, we apply a linear interpolation between them.\n",
        "\n",
        "---\n",
        "\n",
        "You can add (submit) as many pre-post spike relationships as you want - each time you do so, the plots will be updated. Keep in mind, that once you change the parameters in the first tab, you have to start over."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c39bf886c27dd157",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-28T12:03:27.943256Z",
          "start_time": "2024-10-28T12:03:26.951239Z"
        },
        "id": "c39bf886c27dd157"
      },
      "outputs": [],
      "source": [
        "iplot_stdp_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2.1 Assignments: Calculation by Hand\n",
        "\n",
        "**Assignment 8**: Select a random (negative) time for neuron $i$ so that it fires a spike before neuron $j$. Without pressing the submit button, calculate the weight change $\\Delta w_{ij}$. After calculating, press submit and compare your result with the solution shown in the plot. Is your calculation identical to the solution shown by the algorithm? Repeat this exercise, but this time, make neuron $j$ fire before neuron $i$.\n",
        "\n",
        "**Assignment 9**: Find the submitted value in the plot in the third row.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2.2.2 Assignments: Create several spikes\n",
        "\n",
        "**Assignment 10**: Define and submit $10$ different $\\Delta t$ where neuron $i$ fires **before** neuron $j$ and $10$ cases where neuron $i$ fires **after** neuron $j$. How does the time-weight change curve look like?\n",
        "\n",
        "**Assignment 11**: Repeat the experiment after adjusting the parameters in the first tab. Answer the questions below:\n",
        "\n",
        "- How does $A_+$ and $A_-$ influence the weight change?\n",
        "- What is the role of $\\tau_+$ and $\\tau_-$?"
      ],
      "metadata": {
        "id": "jWRSEAnwg7i2"
      },
      "id": "jWRSEAnwg7i2"
    },
    {
      "cell_type": "markdown",
      "id": "f972f64b-8ea7-4bf5-9d72-903d383f9357",
      "metadata": {
        "id": "f972f64b-8ea7-4bf5-9d72-903d383f9357"
      },
      "source": [
        "# 3. Encoding Odor Identity\n",
        "\n",
        "In this third exercise, we will simulate a neural network inspired by the structure of the anterior piriform cortex (APC), a brain region responsible for encoding odor identity in mammals.<br>\n",
        "This exercise is divided into two sections: The first section introduces the biological basis of odor identity encoding, while the second section simulates it in a neural network. For each section, you will be asked to answer the questions at the end (one or two sentences are enough).\n",
        "\n",
        "#### Acronyms\n",
        "- **APC**: Anterior Piriform Cortex\n",
        "- **OE**: Olfactory Epithelium\n",
        "- **OSN**: Olfactory Sensory Neuron\n",
        "- **OR**: Olfactory Receptor\n",
        "- **OB**: Olfactory Bulb\n",
        "- **LOT**: Lateral Olfactory Tract\n",
        "- **MTC**: Mitral/Tufted Cell\n",
        "- **PN**: Pyramidal Neuron\n",
        "- **PV-IN**: Parvalbumin Interneuron\n",
        "- **SST-IN**: Somatostatin Interneuron\n",
        "- **VIP-IN**: Vasoactive Intestinal Peptide Interneuron\n",
        "- **LTP**: Long Term Potentiation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b529fa220287948",
      "metadata": {
        "id": "8b529fa220287948"
      },
      "source": [
        "## 3.1 Biology\n",
        "\n",
        "### 3.1.1 Smell\n",
        "The smell of freshly brewed coffee is the result of various odorants activating olfactory sensory neurons (OSNs) by binding to olfactory receptors (ORs) in the nasal olfactory epithelium (OE) (Figure 1 $\\textbf{A}$). Each OSN expresses one specific OR-subtype which is tuned to particular physicochemical properties of molecules.  \n",
        "Axons of OSNs expressing identical OR-subtypes converge onto the same glomerulus in the olfactory bulb (OB), creating a highly ordered input structure.\n",
        "\n",
        "\n",
        "<figure>\n",
        "    <center>\n",
        "        <img src=\"https://github.com/ManteLab/Iton_notebooks_public/raw/refs/heads/main/utils_ex10/Figures/IFig1.png\"/>\n",
        "        <figcaption align = \"justify\"> <b>Figure 1: Mouse olfactory system and odor identity encoding in the APC: A) </b>  Odorants bind to ORs on OSNs. Axons of OSNs expressing identical OR subtypes converge onto the same glomerulus. In the OB, signal preprocessing occurs before MTCs relay the input to PNs in the APC. Inhibitory neurons are shown in red. Adapted from <a href=\"#ref\">Shepherd (1991)</a> with inspiration from <a href=\"#ref\">Uchida et al. (2014)</a>. <b> B1) </b> Afferent input via L1a (axons of MTCs) activates a subset of PNs (triangles), while many neurons either remain below their threshold level or are not activated at all. <b> B2) </b> Active PNs recruit additional cells into the neuronal ensemble through recurrent intracortical connections, but only if these neurons have already received input via afferents. Recurrent input alone is not strong enough to recruit inactive neurons. </figcaption>    \n",
        "    </center>\n",
        "</figure>\n",
        "\n",
        "\n",
        "\n",
        "### 3.1.2 Anterior piriform Cortex \\& odor identity encoding\n",
        "The piriform cortex, a three-layered paleocortex, receives direct input from the OB via axons of Mitral and Tuftet cells (MTCs). Interestingly, the topographical order of the input, meticulously maintained throughout the OB, is lost as the axons of the MTCs project diffusely to the APC.\n",
        "\n",
        "Pyramidal neurons (PNs) in the APC receive afferent input from MTCs at the distal part of their apical dendrite (Figure 1 $\\textbf{B1}$). To consistently activate a PN, it takes 5-10 co-active MTCs.\n",
        "As a result, only a tiny subset of PNs fire, while the remaining cells may experience depolarization below their activation threshold. The active subset of neurons recruits additional PNs into the ensemble through recurrent intracortical connections, targeting the PNs dendrites closer to the soma (Figure 1 $\\textbf{B2}$). The recurrent activation is strong enough to activate the previously depolarized neurons but too weak to recruit PNs that did not receive any signal from the OB at all. As network activity intensifies, recurrent inhibition is triggered, suppressing the response of neurons recruited later in the process. Consequently, odor identity is encoded by unique ensembles of active neurons in a concentration-invariant manner within the APC.\n",
        "\n",
        "The strengthening of recurrent intracortical synapses between PNs is hypothesized to be the driving force behind the formation of long-lasting ensemble odor representations.\n",
        "\n",
        "### 3.1.3 Disinhibitory circuit\n",
        "\n",
        "With their synapses close to the soma of PNs, parvalbumin interneurons (PV-INs) exert rapid and potent inhibition and are thought to be critical in establishing the sparse and distributed activity patterns within PN ensembles.\n",
        "The inhibitory synapses of somatostatin-positive interneurons (SST-INs) on the proximal apical dendrite of PNs, however, are optimally located to regulate intracortical synaptic plasticity. [Canto-Bustos et al. (2022)](#ref) showed that long-term potentiation (LTP) in those PN-to-PN synapses can be gated by inactivating SST-INs and that vasoactive intestinal polypeptide (VIP) expressing cells are responsible for strong inhibition of those SST-INs.\n",
        "A teaching signal that activates this disinhibitory VIP-to-SST-to-PN circuit could shape neuronal ensemble formation and may be recruited on novel, salient, or emotionally relevant odors.\n",
        "\n",
        "<figure>\n",
        "    <center>\n",
        "        <img src=\"https://github.com/ManteLab/Iton_notebooks_public/raw/refs/heads/main/utils_ex10/Figures/IFig3.png\"/>\n",
        "        <figcaption align = \"center\"> <b>Figure 2: Simplified APC microcircuit: </b> Odor input arrives diffusely at the apical dendrites of PNs. PNs recurrently project to other PNs uniformly throughout the APC. Connections to inhibitory SST- and PV-INs, lead to feedback inhibition. A teaching signal can activate the disinhibitory VIP-SST-PN circuit and open a window for LTP in intracortical PN-to-PN connections. </figcaption>    \n",
        "    </center>\n",
        "</figure>\n",
        "\n",
        "\n",
        "Based on this model, we will develop a simplified version of the APC microcircuit (Figure 2) and explore the effect of a teaching signal that activates the disinhibitory VIP-to-SST circuit during odor learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ba99675f85bf6b6",
      "metadata": {
        "id": "1ba99675f85bf6b6"
      },
      "source": [
        "## 3.2 Assignments\n",
        "\n",
        "\n",
        "**Assignments 12:** Can different OR subtypes show affinity to the same molecule?\n",
        "\n",
        "**Assignments 13:** Do you expect that without a teaching signal, odor identity is not learned at all? Name a learning algorithm that does not require a teaching signal."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34633b635ba774f7",
      "metadata": {
        "id": "34633b635ba774f7"
      },
      "source": [
        "## 3.3. Simulation\n",
        "\n",
        "### 3.3.1 Network\n",
        "<a id='eq'></a>\n",
        "We will use a rate-based model, which means that we will not model the spiking of the neurons themselves. Rather, we will model the membrane potential of the neurons using first-order differential equations and then use a non-linear activation function to convert it into instantaneous activity. Our network will consist of 50 Pyramidal neurons (PN's), 8 SST neurons, 4 PV neurons and 1 VIP neuron.\n",
        "\n",
        "You do not need to understand the model. However, interested students are encouraged to look at the differential equations and the code of the class `APC_circuit` inside the file `utils_ex10/odor.py`\n",
        "\n",
        "<details>\n",
        "<summary><b>Differential Equations</b></summary>\n",
        "\n",
        "The following differential equations describe the membrane potential of our neurons:\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{d\\vec{V}_{PN}}{dt} ={} & W_{Input}^{PN} \\cdot \\vec{x}(t) + W_{PN}^{PN} \\cdot \\vec{r}_{PN}(t) -k_{PN} \\vec{V}_{PN}(t)\\\\ & - \\min\\left(W_{Input}^{PN} \\cdot \\vec{x}(t),W_{SST}^{PN} \\cdot \\vec{r}_{SST}(t)\\right) - W_{PV}^{PN} \\cdot \\vec{r}_{PV}(t) \\\\[1em]\n",
        "\\frac{d\\vec{V}_{PV}}{dt} ={} & W_{PN}^{PV} \\cdot \\vec{r}_{PN}(t)-k_{PV} \\vec{V}_{PV}(t)\\\\[1em]\n",
        "\\frac{d\\vec{V}_{SST}}{dt} ={} & W_{PN}^{SST} \\cdot \\vec{r}_{PN}(t) -k_{SST} \\vec{V}_{SST}(t) - W_{VIP}^{SST} \\cdot \\vec{r}_{VIP}(t) \\\\[1em]\n",
        "\\frac{d\\vec{V}_{VIP}}{dt} ={} & \\vec{\\tau}(t) -k_{VIP} \\vec{V}_{VIP}(t) \\\\[1em]\n",
        "\\vec{r}_X(t) ={} & ReLU(\\vec{V_X}(t)) = \\max(0,\\min((\\delta_X \\cdot \\vec{V_X}(t) - \\theta_X), r_X^{max}))\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "| Parameter     | Value         | Name in Code  | Explanation   |\n",
        "| :------------ | :------------ | :------------ | :------------ |\n",
        "|  $\\vec{V}_{X}$ |  $\\mathbb{R}$ | V\\_{X} | Membrane potential of X |\n",
        "|  $r_{X}(t)$ | $\\mathbb{R}_+^{n}$ | Activity\\_X | Activity (rate) of X |\n",
        "|  $r_X^{max}$ | $\\mathbb{R}_+$ | Rmax\\_X | Maximal activity (rate) of X |\n",
        "|  $k_{X}$ | const.  | k\\_X | EPSP decay rate for X|\n",
        "|  $W_{X}^{Y}$ | $\\mathbb{R}_+^{n \\times m}$ | weightX\\_Y |  Weight matrix for $X\\to Y$ connection <br> with $n = \\#Y$ and $m = \\#X $ <br> only $W_{PN}^{PN} $ is time dependent |\n",
        "|  $\\vec{x}(t)$ | $\\mathbb{N}_+^n$ | input | Input at time $t$ |\n",
        "|  $\\tau(t)$ |  const. | teacher | Magnitude of teacher input |\n",
        "|  $\\bar{r}(t)$ | $\\mathbb{R}_+$ |  r\\_avrg | Average rate from $T-t$ to $t$ |\n",
        "|  T | 100 $ms$ | timeAvrg | Time-window of integration  <be> for weight update |\n",
        "|  $\\alpha$ | 0.8 | alpha | Rate of regularization in OJA |\n",
        "|  $\\lambda$ | $1.2 \\times 10^{-6}$ | learning\\_rate | Learning rate |\n",
        "|  $\\theta$ | $\\mathbb{R}_+$ | Thresh\\_X | Activity threshold |\n",
        "|  $\\delta$ | $\\mathbb{R}_+$ | Gain\\_X | Activity gain |\n",
        "|  $dt$ | 1 ms | -- | Time increment |\n",
        "\n",
        "$$X,Y \\in \\{PN,SST,PV,VIP\\}$$\n",
        "\n",
        "\n",
        "\n",
        "We model the differential equations using the [forward Euler](https://en.wikipedia.org/wiki/Euler_method) method with a time-step of $dt = 1~ms$.\n",
        "\n",
        "</details>\n",
        "\n",
        "### 3.3.2 Odor\n",
        "We model odor as binary vectors. A \"$1$\" indicates the presence of a certain odorant in the odor, and a \"$0$\" indicates its absence. For simplicity, we restrict the size of an odor to $10$ different odorants and define that an odor always consists of $2$ odorants.\n",
        "One of the odors will be linked to a teaching signal and one odor will function as a control. These two odors will be presented in an alternating fashion to our neuronal network. Further, random odors are presented to the network to test the noise resistance of the network (Figure 3).\n",
        "\n",
        "\n",
        "<figure>\n",
        "    <center>\n",
        "        <img src=\"https://github.com/ManteLab/Iton_notebooks_public/raw/refs/heads/main/utils_ex10/Figures/MFig2.png\"/>\n",
        "        <figcaption align = \"justify\"> <b>Figure 3: Odor distribution.</b> Blue odors are linked to a teaching signal and darkgray inputs serve as controls. Additional random odors are presented during training to evaluate learning with noisy input.\n",
        " </figcaption>    \n",
        "    </center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dd7903c4c953621",
      "metadata": {
        "id": "6dd7903c4c953621"
      },
      "source": [
        "## 3.4 Simulation\n",
        "\n",
        "The function below implements the network with Odor input. We will not go into the details of the model itself but observe what happens when such a network is trained. We have three different modes.\n",
        "\n",
        "**No Learning**:\n",
        "\n",
        "The network is initialized randomly and the Odor signal is fed through the network. Thereby, the weights remain the same\n",
        "\n",
        "**Hebbian Learning**:\n",
        "\n",
        "One of the simplest unsupervised learning rules is Hebbian learning. It is defined as:\n",
        "\n",
        "$$\\frac{\\Delta w}{\\Delta t} = \\lambda \\cdot x \\cdot y $$\n",
        "$$ w(t)  = w(t-1) +  \\Delta w(t) $$\n",
        "\n",
        "Where $x = r(t-1)$ is the presynaptic activation, $y = r(t)$ is the postsynaptic activation, $w$ is the weight between the neurons and $\\lambda$ is the learning rate.\n",
        "\n",
        "We implement learning only for the recurrent PN-to-PN connections.\n",
        "\n",
        "**Oja Learning**:\n",
        "\n",
        "As you know, neurons have limited resources and the weights between synapses (e.g., the number of AMPA receptors) cannot increase indefinitely. Furthermore, neurons tend to normalize their activity to a given baseline. A Hebbian-based learning rule that incorporates this concept is Oja's learning rule:\n",
        "\n",
        "<a id='oja'></a>\n",
        "$$\\Delta W(t) = \\frac{\\lambda}{T}\\left[\\int_{t - T}^{t} \\vec{r}(u) \\vec{r}^\\top(u-1) du - W \\alpha \\int_{t - T}^{t} \\overline{r}(u)^2 du\\right]$$\n",
        "\n",
        "Weight update:\n",
        "$$ W(t)  = W(t-1) +  \\Delta W(t) $$\n",
        "\n",
        "To make the learning rule smoother, we average over a time window specified in the variable `self.timeAvrg` which is set to $100~ms$. Since we are modeling time in discrete steps, we are actually summing and not integrating."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef809d76-b2da-410a-ba68-08ab7d6231ff",
      "metadata": {
        "id": "ef809d76-b2da-410a-ba68-08ab7d6231ff"
      },
      "source": [
        "### 3.4.1 Simulation\n",
        "\n",
        "Execute the cell below. Read the eplanatory text and attend to **assignments 14-18** embedded within the tabs of the visualization below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17a624b6-f3b7-4c8f-9559-4dae3f3c2ffa",
      "metadata": {
        "id": "17a624b6-f3b7-4c8f-9559-4dae3f3c2ffa"
      },
      "outputs": [],
      "source": [
        "odor_model()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
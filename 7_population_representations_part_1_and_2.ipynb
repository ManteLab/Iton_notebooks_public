{"cells":[{"cell_type":"markdown","metadata":{"id":"M5xuecR1Fes6"},"source":["# Introduction to Neuroinformatics\n","\n","## Exercise session 7 (Part 1): Analysis of high-dimensional data\n","\n","Welcome to the seventh exercise session of the introduction to neuroinformatics course. In this notebook you will be presented with:\n","1. Geometric view of data and two types of dimensionality reduction methods,\n","2. Context-dependent models: Choose the right level of description and the right method to distinguish between different implementations of the same function, and\n","3. Analyzing Representations in Deep Networks (Alexnet) (in a separate notebook).\n","\n","If you wish to be able to save your progress, click \"File\" -> \"Save a copy in Drive\".\n"]},{"cell_type":"markdown","metadata":{"id":"R4aFAV1_Fes9"},"source":["---\n","\n","# Table of contents\n","* [Packages](#packages)\n","* [1: Geometric View of Data](#gvod)\n","    * [1.1: Finding New Bases](#fnb)\n","    * [1.2: Projecting Onto the New Basis](#potnb)\n","* [2: Context-dependent Models](#cdm)\n","    * [2.1: Single Unit Analysis](#sua)\n","        * [2.1.1: Encoding Models](#em)\n","    * [2.2: 1-d Population-level Analysis](#pla)\n","    * [2.3: 2-d Population-level Analysis](#2pla)\n","        * [2.3.1: PCA](#pca)\n","        * [2.3.2: TDR](#tdr)\n"]},{"cell_type":"markdown","metadata":{"id":"RxhEIztIHkRy"},"source":["---\n","\n","# Packages <a name=\"packages\"></a>\n","The following cells are used to install the necessary packages and libraries for the exercise:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ww_5EeYVH_YC"},"outputs":[],"source":["!which python  # This displays which python is being used\n","!pwd # This displays the current directory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3gUVomsbFes-"},"outputs":[],"source":["# Create a directory to store the files in utils_ex7/data_ctx\n","!mkdir utils_ex7\n","!mkdir -p utils_ex7/data_ctx\n","\n","!wget -P utils_ex7/ https://github.com/ManteLab/Iton_notebooks_public/raw/refs/heads/main/utils_ex7/geometry_utils.py\n","!wget -P utils_ex7/ https://github.com/ManteLab/Iton_notebooks_public/raw/refs/heads/main/utils_ex7/ctx_dependent_utils.py\n","!wget -P utils_ex7/ https://github.com/ManteLab/Iton_notebooks_public/raw/refs/heads/main/utils_ex7/get_ctx_data_utils.py\n","!wget -P utils_ex7/ https://github.com/ManteLab/Iton_notebooks_public/raw/refs/heads/main/utils_ex7/task.png\n","!wget -P utils_ex7/ https://github.com/ManteLab/Iton_notebooks_public/raw/refs/heads/main/utils_ex7/models_v2.png\n","\n","from utils_ex7.ctx_dependent_utils import *\n","from utils_ex7.geometry_utils import *\n","from utils_ex7.get_ctx_data_utils import *\n","\n","get_ctx_data()"]},{"cell_type":"markdown","metadata":{"id":"6XDhnBPZFes_"},"source":["---\n","\n","# 1. Geometric view of data <a name=\"gvod\"></a>\n","\n","Imagine we have samples that represent the activity (firing rates) of two recorded neurons on different trials. Each point in the scatter plot is the activity on a trial. Trials can be grouped by the motor ouput of the subject (blue for choice 1 and red for choice 2).\n","\n","\n","The mean of each choice-class is fixed, but you can change the covariance matrix within each choice-class by adjusting the slider “Corr Coeff“.\n","\n","You should get a feel for how changing the correlation coefficient affects the geometry of the simulated data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iu9rxin1Fes_"},"outputs":[],"source":["iplot_data()"]},{"cell_type":"markdown","metadata":{"id":"jTK28yv7Fes_"},"source":["---\n","\n","> **Assignment 1**\n",">\n","> What effect do negative correlation coefficient values have?\n","\n","Solution:\n"]},{"cell_type":"markdown","metadata":{"id":"oeCJliq-nNk-"},"source":["---\n","\n","> **Assignment 2**\n",">\n","> What correlation coefficient results in a circular data cloud?\n","\n","Solution:\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"5l6J9iFtFetA"},"source":["## 1.1: Finding new bases <a name=\"fnb\"></a>\n","\n","When we analyze high-dimensional neural data we focus on a low-dimensional subspace. In this section of the tutorial we will introduce two dimensionality reduction methods.\n","1. Principal Component Analysis is a technique used to reduce the dimensionality of data by transforming it into a new coordinate system, where the largest variance by any projection of the data lies on the first axis (called the first principal component), the second largest variance on the second axis, and so on.\n","2. Targeted dimensionality reduction focuses on reducing the dimensionality in a way that aligns with specific features or variables of interest, rather than maximizing overall variance as in PCA.\n","\n","In the first pasectionrt of this notebook we will explore how multivariate data can be represented in different bases. For PCA, the new basis is the one spanned by the Principal Components explaining the highest portion of variance in descending order.\n","\n","For TDR, we define an orthonormal basis by finding task-relevant axes (as opposed to high-variance axes). We begin by describing the response $r_{i,t}(k)$ of unit $i$ at time $t$ on trial $k$ as a linear combination of several task variables:\n","\n","\\begin{align*}\n","  r_{i,t}(k) = \\beta_{i,t}(1) \\mathrm{choice}(k) + \\beta_{i,t}(2) \\mathrm{input_{strength}}(k)\\\\\n","\\end{align*}\n","\n","Make sure you understand the equation above. Why does $\\mathrm{choice}(k)$ depend on $k$ but not on $t$?\n","The regression coefficients describe how much the trial-by-trial firing rate of unit $i$ depends on the corresponding task variable $v=1,2$. We use these regression coefficients to identify dimensions in state space containing task related variance.\n","\n","For each task variable v = 1,2 we first build a set of coefficient vectors $\\vec{\\beta}_{v,t}$ whose entries $\\beta_{v,t}(i)$ correspond to the regression coefficient for task variable $v$, time $t$ and unit $i$. Each vector $\\vec{\\beta}_{v,t}$ corresponds to a direction in state space that accounts for variance in the population response at time $t$, due to variation in task variable $v$.\n","\n","Finally we obtain orthogonal axes of choice and input strength by orthogonalizing the regression vectors with QR-decomposition. The resulting axes span the same 'regression subspace' as the original regression vectors, but crucially each explain distinct portions of the variance in the responses.\n"]},{"cell_type":"markdown","metadata":{"id":"CyIarw_TFetB"},"source":["---\n","\n","\n","## 1.2: Projecting onto the new basis <a name=\"potnb\"></a>\n","\n","Lastly, we will express our data in the new basis that we have just found, by projecting the data into our new basis using matrix multiplication: $\\mathbf{Y} = \\mathbf{X}\\mathbf{W}$, where $\\mathbf{Y}$ is the data in the new basis, $\\mathbf{W}$ is the basis (either the principal components in PCA or $[\\vec{\\beta}_{\\mathrm{choice}}, \\vec{\\beta}_{\\mathrm{input}}]$ in TDR) and $\\mathbf{X}$ is the data in the original basis (the full neural space for example). For one time point, the dimensionality of $\\mathbf{X}$ is $N_{units} \\times 1 $, the dimensionality of $\\mathbf{W}$ is $N_{units} \\times N_{coeffs}$ and the dimensionality of $\\mathbf{Y}$ is $N_{coeffs} \\times 1$, where $N_{units}$ is the number of units and $N_{coeffs}$ is the number of axes (in PCA the number of principal components we keep and in TDR the number of task variables).\n","\n","In this section of the tutorial you should understand how the identified principal components relate to the geometry of the data. In the second section, you will see how to choose the number of principal components to further analyze by looking at their variance explained.\n","\n","We display the effects of PC1 and TDR-choice axis by plotting a histogram of projections for choice 1 and a histogram of projections for choice 2 to highlight how well each method separates the two choices (a <ins>classification problem</ins>). For TDR-input we use a scatter plot to highlight whether the linear increase of input strength is preserved across the identified axis (a <ins>regression problem</ins>)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vMHWpNhGoVri"},"outputs":[],"source":["iplot_data_2classes()"]},{"cell_type":"markdown","metadata":{"id":"esh3TsMlFetB"},"source":["---\n","\n","> **Assignment 3**\n",">\n","> Which method is better when corr-coeff is negative? What about when corr-coeff is positive?\n","\n","Solution:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"R9rQupZGnuvv"},"source":["---\n","\n","> **Assignment 4**\n",">\n","> What is the effect of orthogonalization order (input strength first vs. choice first) on the identified task relevant subspace?\n","\n","Solution:\n","\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"ctO2S7q7FetB"},"source":["# 2. Context-dependent models <a name=\"cdm\"></a>"]},{"cell_type":"markdown","metadata":{"id":"NTIpFq1pFetB"},"source":["In the second section of this notebook we will give you 4 datasets. What these datasets have in common is that they all achieve the same function, but through different implementations. Your task will be to distinguish the different implementations by choosing the right level of description: single-unit or population-level response and by  applying the methods introduced in the previous section: PCA, TDR, order of orthogonalization.\n","\n","<ins>The behavioral task:</ins> All 4 datasets implement selective integration. On each trial, two inputs are presented, a motion input and a color input, of different strengths. Depending on the context, motion context or color context, the subject needs to integration the relevant input (motion input in motion context and color input in color context) and ignore the irrelevant input (motion input in color context and color input in motion context).\n","\n","The motion input has two directions. On correct trials, motion to the right is associated with a choice to the right (choice 1) and motion to the left is associated with a choice to the left (choice 2). Similarly, the color input has two directions. On correct trials, red is associated with a choice to the right (choice 1) and green is associated with a choice to the left (choice 2). We will only analyze correct trials. Each input has 3 different strengths (weak 5, medium 15, strong 50) for each choice (-50, -15, -5 for choice 2 and 50, 15, 5 for choice 1).\n","\n","In the figure below you can see the task might look like (a) and the stimulus set (b).\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H4wus1xsFetC"},"outputs":[],"source":["show_task()"]},{"cell_type":"markdown","metadata":{"id":"tzqX_fNwFetC"},"source":["---\n","\n","> **Assignment 5**\n",">\n","> How can you interpret the psychophysical curves in c-f? Why are c & d different? Why are c & f similar?\n","\n","Solution:\n","\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"j53F6sGdFetC"},"source":["The 4 datasets differ with respect to the relative directions and context dependence of the choice axis (red lines) and the inputs (black and blue lines).\n","\n","<ins>Model 1: Early selection.</ins> When relevant, the motion input pushes the population response along the choice axis. When irrelevant, the motion input is filtered out before and thus exerts not effect on choice. Motion input is aligned with choice in motion context (top row, left panel) and color input is aligned with choice in color context (bottom row, right panel). Color input is not present in motion context (top row, right panel - no blue line) and motion input is not present in color context (bottom row, left panel - no black line).\n","\n","<ins>Model 2: Context-dependent input direction.</ins> Motion input direction varies between contexts, whereas the choice axis is stable (red line is consistent across both contexts - top and bottom row). Inputs are selected based on the basis of their projection onto the choice axis. Motion input is aligned with choice axis in motion context (top row, left panel) and color input is aligned with choice axis in color context (bottom row, right panel). Motion input is orthogonal to choice axis in color context (bottom row, left panel) and color input is orthogonal to choice axis in motion context (top row, right panel). Motion axis (black line) is different between motion context and color context (left panel, top and bottom row) and similarly, color axis (blue line) is different between the two contexts. In this mechanism, the output direction is abstract.\n","\n","<ins>Model 3: Context-dependent output direction.</ins> Choice axis varies between contexts, whereas motion input direction is stable (blue/black lines have same direction in the two context, top and bottom row). Inputs are selected based on the basis of their projection onto the choice axis. Motion input is aligned with choice axis in motion context (top row, left panel) and color input is aligned with choice axis in color context (bottom row, right panel). Choice axis is different between the two contexts (in motion context the red axis is horizontal, top row and in color context the red axis is vertical, bottom row). In this mechanism, the input direction is abstract.\n","\n","<ins>Model 4: Context-dependent selective integration.</ins> All axes (motion, color and choice) are stable across contexts. The same input (motion) leads to integration in motion context, but is ignored in the color context. This is a new mechanism that will be presented in Lecture 9. For now it is important to understand that the input axes are coupled to the choice axes in a context-dependent manner and that this is the only mechanism where all three axes are abstract.\n","\n","The concept of Abstraction was introduced on Slide 38-42 of Lecture 7 (Possible Geometries)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4M75-MzpFetC"},"outputs":[],"source":["show_models_geometry()"]},{"cell_type":"markdown","metadata":{"id":"GZHPkntmFetC"},"source":["Load the datasets:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5eb2AUxqFetC"},"outputs":[],"source":["# Run without changing\n","model_a = load_context_dependent_models('model_a')\n","model_b = load_context_dependent_models('model_b')\n","model_c = load_context_dependent_models('model_c')\n","model_d = load_context_dependent_models('model_d')"]},{"cell_type":"markdown","metadata":{"id":"9dGtNCRTFetD"},"source":["---\n","\n","## 2.1: Single unit analysis <a name=\"sua\"></a>"]},{"cell_type":"markdown","metadata":{"id":"-UUw5xJ_FetD"},"source":["<ins>The neural data:</ins> You have the activity of 500 units recording during input presentation. For the rest of the notebook we will look at condition-averages, where we group trials according to certain conditions and observe the averaged activity."]},{"cell_type":"markdown","metadata":{"id":"fdjJZcXbFetD"},"source":["Below you can visualize condition-averages. Each time you run the cell below, you will see the condition-averaged activity of 6 randomly selected neurons.\n","- In the first row, trials are sorted by choice (continuous line for choice 1 vs dashed line for choice 2 across all trials).\n","- In the second row, trials are sorted by the strength of motion input (weak in light grey to strong in black) and choice (same continuous vs dashed line as above) and only trials for motion context are considered.\n","- In the third row, the same split of data but now for color input and color context.\n","- In the fourth row, trials are sorted by context (motion in black and color in blue) and choice (same continuous vs. dashed line) for all trials."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zcoCXgJ9FetD"},"outputs":[],"source":["plot_psths(model_a)"]},{"cell_type":"markdown","metadata":{"id":"WVeHqSwSFetD"},"source":["---\n","\n","> **Assignment 6**\n",">\n","> Plot condition averaged (PSTHs) from all four models. Can you identify some PSTHs that are specific to a model? What about PSTHs that are common across models?\n","\n","Solution:\n","\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"01x20IF9FetD"},"source":["### 2.1.1: Encoding models <a name=\"em\"></a>\n","\n","How do you determine if a neuron is selective to a behavioral variable? This regression equation was introduced on Slide 57 (not numbered?) of Lecture 7. The intercept is (5) as opposed to (1) - what is on the Lecture Slides.\n","\n","We use multi-variable linear regression to determine how various task variables affect the responses of each unit.\n","\\begin{align*}\n","  r_{i,t}(k) = \\beta_{i,t}(1) \\mathrm{choice}(k) + \\beta_{i,t}(2) \\mathrm{motion_{strength}}(k) + \\beta_{i,t}(3) \\mathrm{color_{strength}}(k) + \\beta_{i,t}(4) \\mathrm{context}(k) + \\beta_{i,t}(5)\\\\\n","\\end{align*}\n","\n","In the top row of the figure below, we plot the regression coefficients estimated with the equation above against each other. Each point is a neuron. Notably, we estimate these regression coefficients from all trials. Moreover, as seen in the equation above, we estimate a set of regression coefficients at each time, but in the plots below we will only focus on one time point. For each regression coefficient we selected the time point where the absolute value was the highest.\n","\n","In the bottom row, we estimate the regression coefficients for each context separately, i.e. we will estimate $\\beta_{i,t}(1)$ for choice, $\\beta_{i,t}(2)$ for motion input and $\\beta_{i,t}(3)$ for color input separately for motion context, resulting in choice(motion), motion(motion) and color(motion). Similary, we estimate them for the color context and obtain choice(color), motion(color) and color(color)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uo1ha9D_FetD"},"outputs":[],"source":["plot_tunings(model_a)\n","#plot_tunings(model_b)\n","#plot_tunings(model_c)\n","#plot_tunings(model_d)"]},{"cell_type":"markdown","metadata":{"id":"m7b3T1-0FetD"},"source":["---\n","\n","> **Assignment 7**\n",">\n","> What means a positive $\\beta_{i,t}$? What about a negative $\\beta_{i,t}$?\n","\n","Solution:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Rojs-T4bpt4U"},"source":["---\n","\n","> **Assignment 8**\n",">\n","> What is the difference between $\\beta_{i,t}$ = 0.5 and $\\beta_{i,t}$ = 4?\n","\n","Solution:\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yfq4cekCqMXf"},"source":["---\n","\n","> **Assignment 9**\n",">\n","> What does it mean when $\\beta_{i,t}(1)$ (for choice) vs $\\beta_{i,t}(2)$ (for motion) is a circular data cloud? What about when it is an ellipse?\n","\n","Solution:\n"]},{"cell_type":"markdown","metadata":{"id":"rQfznwt9FetE"},"source":["---\n","\n","> **Assignment 10**\n",">\n","> Do any of the models have $\\beta_{i,t}(1)$ (for choice in color context) vs $\\beta_{i,t}(1)$ (for choice in motion context) as a circular data cloud? What does this mean for the choice axis?\n","\n","Solution:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tM-MSaiTp1Ov"},"source":["---\n","\n","> **Assignment 11**\n",">\n","> Summarizing the Single-unit analysis section. Can you distinguish between the models by looking at the single unit properties? If not completely, can you at least rule out some associations, for e.g. make statements of the type 'model_a is definitely model 1'?\n","\n","Solution:\n"]},{"cell_type":"markdown","metadata":{"id":"EaaY4VEYFetE"},"source":["---\n","\n","## 2.2: 1-d Population-level analysis <a name=\"pla\"></a>"]},{"cell_type":"markdown","metadata":{"id":"N7swSTwoFetE"},"source":["Next we will study the population as a whole. We will reduce the dimensionality of the dataset from 500 dimensions to 4 dimensions with PCA and 3 dimensions with TDR. Both these two methods were introduced in the first section of the notebook.\n","\n","In TDR we can investigate whether the chosen task variables are represented in the neural population by computing a time-dependent Frobenius norm."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nVV8MszqFetE"},"outputs":[],"source":["# Run without changing\n","\n","plot_beta_norm(model_a, model_b, model_c, model_d)"]},{"cell_type":"markdown","metadata":{"id":"gH7pNaQKFetE"},"source":["---\n","\n","> **Assignment 12**\n",">\n","> Which task variable has the highest norm?\n","\n","Solution:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qKoot9ImqvW-"},"source":["---\n","\n","> **Assignment 13**\n",">\n","> Which do some task variables have a constant norm and some a time-dependent norm?\n","\n","Solution:\n"]},{"cell_type":"markdown","metadata":{"id":"ZLj4EMrXFetE"},"source":["---\n","\n","In PCA we can look at variance explained by each PC. The y-axis on the left shows the cumulative variance explained (blue - it increases and it approaches 100) and the y-axis on the right shows the log-scale of variance explained (green - it decreases and when plotted on a log-scale it shows this sharp transition)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mfCy5_fQFetE"},"outputs":[],"source":["# Run without changing\n","\n","plot_pca_var_explained(model_a, model_b, model_c, model_d)"]},{"cell_type":"markdown","metadata":{"id":"a4Q-IiokFetE"},"source":["---\n","\n","> **Assignment 14**\n",">\n","> Inspecting the figure above, how many principal components would you choose for further analyses?\n","\n","Solution:\n"]},{"cell_type":"markdown","metadata":{"id":"OudNgJYXFetI"},"source":["---\n","\n","Relevant input: motion input in motion context or color input in color context\n","- 6 conditions (-50, -15, -5 for choice 2 and +50, +15, +5 for choice 1)\n","\n","Irrelevant input: motion input in color context or color input in motion context\n","- 12 conditions (-50, -15, -5, 5, 15, 50 for choice 1 and -50, -15, -5, 5, 15, 50 for choice 2)\n","\n","\n","Filled circles represent when the input (relevant or irrelevant) points towards choice 1 and open circles when the input points towards choice 2. The color-intensity represents the input strength (black, grey, light grey for strong, medium, weak motion input respectively and dark blue, medium blue, light blue for strong, medium, weak color input).\n","\n","Below you can use PCA or TDR to visualize 1-d trajectories. The y-axis illustrates the projection value and the x-axis illustrates time.\n","\n","For PCA you can run: plot_projections_1d(model_a, 'pca') and select the model: model_a, model_b, model_c, model_d\n","\n","For TDR you can run: plot_projections_1d(model_a, 'tdr', ['input_motion','input_color', 'choice']). The last argument determines the order of orthogonalization. You can choose between:\n","\n","['input_motion', 'choice', 'input_color']\n","\n","['choice', 'input_motion', 'input_color']\n","\n","['input_motion','input_color', 'choice']\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iNll5VKgFetI"},"outputs":[],"source":["# Here you can select the method (pca or tdr), the context (motion or color) and the order of orthogonalization (relevant only for tdr). We provide example for the different ways to run it below:\n","\n","#context = 'color'\n","context = 'motion'\n","\n","#order_orthogonalization = ['input_motion',  'input_color', 'choice']\n","order_orthogonalization = ['input_motion', 'choice', 'input_color']\n","#order_orthogonalization = ['choice', 'input_motion', 'input_color']\n","\n","plot_projections_1d(model_c, 'pca', [], context)\n","#plot_projections_1d(model_b, 'tdr', order_orthogonalization, context)\n"]},{"cell_type":"markdown","metadata":{"id":"RM-hpyz3FetI"},"source":["Make sure you understand why in some cases you have 6 lines and in some cases you have 12 lines.\n","\n","How the order_orthogonalization affects the projections was explained in class (see Slides 36-43 of Exercise Session 7 (Population Representations)).\n","\n","The correct way of orthogonalizing is: order_orthogonalization = ['choice', 'input_motion', 'input_color']\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FHmJ5ut4rYO_"},"source":["---\n","\n","> **Assignment 15**\n",">\n","> Can you relate the time profile of TDR projections with the Frobenius norm estimated above?\n","\n","Solution:\n"]},{"cell_type":"markdown","metadata":{"id":"IZCVy1v5rjJg"},"source":["---\n","\n","> **Assignment 16**\n",">\n","> Can you relate the strength of PCA projections and the variance explained estimated above?\n","\n","Solution:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vZXgfvuPFetI"},"source":["---\n","\n","## 2.3: 2-d Population-level analysis <a name=\"2dp\"></a>\n","\n","\n","Same conditions as for 1-d projections. For 2-d projections we plot time-dependent trajecties of two axes against each other (for e.g. pc1 vs. pc2, or choice vs. motion input). The start of the trajectories is marked by the purple circle in all plots below.\n"]},{"cell_type":"markdown","metadata":{"id":"0xYo8AjOFetI"},"source":["---\n","\n","### 2.3.1: PCA <a name=\"pca\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fYA3b5W2FetJ"},"outputs":[],"source":["# Here you can select the context.\n","\n","#context = 'color'\n","context = 'motion'\n","\n","plot_projections_2d(model_a, 'pca', [], context)"]},{"cell_type":"markdown","metadata":{"id":"9T4VO-SDFetJ"},"source":["---\n","\n","> **Assignment 18**\n",">\n","> Is there any structure that is visible in 2-d projections but was not apparent in 1-d projections when using PCA?\n","\n","Solution:\n"]},{"cell_type":"markdown","metadata":{"id":"YBJ3oxrTFetJ"},"source":["---\n","\n","### 2.3.2: TDR <a name=\"tdr\"></a>\n","\n","We will now build 2-d TDR projections like in Lecture 7, Slide 58 and after (not numbered?).\n","\n","“motion (color)“ refers to motion input axis in color context. So in the figures below, the top row refers to motion context and the bottom row to color context."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lUgybs_pFetJ"},"outputs":[],"source":["# Here you can select the order of orthogonalization and which model you want to analyze.\n","\n","#order_orthogonalization = ['input_motion',  'input_color', 'choice']\n","order_orthogonalization = ['choice', 'input_motion', 'input_color']\n","#order_orthogonalization = ['input_motion', 'choice', 'input_color']\n","\n","\n","plot_projections_2d(model_a, 'tdr', order_orthogonalization)\n","plot_projections_2d(model_b, 'tdr', order_orthogonalization)\n","plot_projections_2d(model_c, 'tdr', order_orthogonalization)\n","plot_projections_2d(model_d, 'tdr', order_orthogonalization)\n"]},{"cell_type":"markdown","metadata":{"id":"03k-84oBFetK"},"source":["---\n","\n","> **Assignment 19**\n",">\n","> Is there any structure that is visible in 2-d projections but was not apparent in 1-d projections when using TDR?\n","\n","Solution:\n"]},{"cell_type":"markdown","metadata":{"id":"k8EmJ7gZtoEl"},"source":["---\n","\n","> **Assignment 20**\n",">\n","> Did you figure out the associations between the datasets (a-d) and the models (1-4)?\n","\n","Solution:\n"]},{"cell_type":"markdown","metadata":{"id":"rXBkQcq0tw8z"},"source":["---\n","\n","# Don't forget to check out the part 3 notebook!"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}